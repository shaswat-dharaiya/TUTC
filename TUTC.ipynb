{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7o5LtG8cJ9b2",
    "outputId": "b55b42bb-24ba-44f4-f6e5-79d40742245b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |███▎                            | 10 kB 13.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 20 kB 14.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 30 kB 17.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 40 kB 20.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 51 kB 23.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 61 kB 26.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 71 kB 28.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 81 kB 25.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 92 kB 27.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 101 kB 9.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
      "Installing collected packages: num2words\n",
      "Successfully installed num2words-0.5.10\n"
     ]
    }
   ],
   "source": [
    "%pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oHU-VKbJn9u"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from num2words import num2words\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "io630J_Zpke6"
   },
   "outputs": [],
   "source": [
    "class Tutc():\n",
    "\n",
    "  # def __init__(self):\n",
    "    \n",
    "    # Applying 0th round of text cleaning techniques\n",
    "  '''\n",
    "  Contracted to decontracted text\n",
    "  Used for verbs extensively\n",
    "  '''\n",
    "  def tutc0(self, text):\n",
    "    if type(text) is str:\n",
    "        text = text.lower()\n",
    "        # specific    \n",
    "        text = re.sub(r\"won\\'t\", \"will not\", text)    \n",
    "        text = re.sub(r\"shan\\'t\", \"shall not\", text)\n",
    "        text = re.sub(r\"ain\\'t\", \"is not\", text)\n",
    "\n",
    "        # general\n",
    "        text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'s\", \" is\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        # text = re.sub(r\"\\'t\", \" not\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text\n",
    "\n",
    "  # Apply a 1st round of cleaning\n",
    "  def tutc1(self, text):\n",
    "    regex = re.compile('[@_!#$%^&-+*()<>?/\\|}{~:]\"') \n",
    "    if type(text) == str:\n",
    "      word_list = text.split()      \n",
    "      for i,word in enumerate(word_list):        \n",
    "        num = re.findall(\"^\\[^\\]^[a-zA-Z]|[0-9]*[.][0-9]+|[0-9]+\", word)\n",
    "        if len(num)>0:          \n",
    "          for x in num:\n",
    "              word_list[i] = word.replace(x,num2words(x))          \n",
    "      return ' '.join(word_list)\n",
    "    elif type(text) == int or type(text) == float:\n",
    "      return num2words(text)\n",
    "      \n",
    "  def tutc2(self, text):\n",
    "    if type(text) is str:\n",
    "      text = re.sub('\\s+', ' ', text)\n",
    "      text = re.sub('\\[.*?\\]', '', text)\n",
    "      text = re.sub(\"\\\\W\",\" \",text)\n",
    "      text = re.sub('http?://\\S+|www\\.\\S+', '', text)\n",
    "      text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "      text = re.sub('<.*?>+', '', text)\n",
    "      text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "      text = re.sub('\\n', '', text)\n",
    "      text = re.sub('\\w*\\d\\w*', '', text)  \n",
    "      text = re.sub(r\"https?:[^s]+\", \"\", text)\n",
    "      text = re.sub('[‘’“”…]', '', text)\n",
    "    return text\n",
    "  \n",
    "  def apply_rounds(self, dataframe, cols):\n",
    "    print('Cleaning process has begun')\n",
    "\n",
    "    dataframe[cols] = dataframe[cols].apply(self.tutc0)\n",
    "    print('Round 0 appliead')\n",
    "\n",
    "    dataframe[cols] = dataframe[cols].apply(self.tutc1)\n",
    "    print('Round 1 appliead')\n",
    "\n",
    "    dataframe[cols] = dataframe[cols].apply(self.tutc2)\n",
    "    print('Round 2 appliead')\n",
    "\n",
    "    print('Data Cleaning process complete.')\n",
    "\n",
    "  def apply_round0(self, dataframe, cols):\n",
    "    print('Cleaning process has begun')\n",
    "\n",
    "    dataframe[cols] = dataframe[cols].apply(self.tutc0)\n",
    "    print('Round 0 appliead')\n",
    "  \n",
    "  def apply_round1(self, dataframe, cols):\n",
    "    print('Cleaning process has begun')\n",
    "\n",
    "    dataframe[cols] = dataframe[cols].apply(self.tutc1)\n",
    "    print('Round 1 appliead')\n",
    "\n",
    "  def apply_round2(self, dataframe, cols):\n",
    "    print('Cleaning process has begun')\n",
    "\n",
    "    dataframe[cols] = dataframe[cols].apply(self.tutc2)\n",
    "    print('Round 2 appliead')\n",
    "\n",
    "  def stop_words_remove(self,text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    \n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "              \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "def remove_stop(self, dataframe, cols):\n",
    "  print('Stop Words removal started')\n",
    "  dataframe[cols] = dataframe[cols].apply(self.stop_words_remove)\n",
    "    print('Stop Words removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKfXFr16kYC4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TUTC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
